{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63e0249e",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ThanosApostolou/aics-pattern-recognition/blob/main/IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1oA4US2rVw3X",
   "metadata": {
    "id": "1oA4US2rVw3X",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INSTALL DEPENDENCIES\n",
    "# Uncomment and run only once.\n",
    "!pip install matplotlib numpy pandas scikit-learn scipy tensorflow pyclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a24235d-b5ff-4fed-8231-bbaf33d6c772",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6IVUxAXvunto",
    "outputId": "a0a10ee7-9d51-4237-8341-1870efd3348d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPORTS AND GLOBAL CONSTANTS\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import typing\n",
    "import numpy.typing as np_typing\n",
    "\n",
    "##MAIN PROGRAM VARIABLES##\n",
    "##(0): dataset: np array of strings\n",
    "##(1): dataframe: original dataset in its primal form\n",
    "##(2): ratings_num_df: new dataframe storing the number of rated items per unique user\n",
    "##(3): ratings_span_df: new dataframe storing the timespan in days for each user\n",
    "##(4): minimum_ratings - maximum_ratings => ratings_df=> (i) final_df\n",
    "\n",
    "# Constants\n",
    "DATASET_FILE_PATH = \"./Dataset.npy\"\n",
    "#Define the figures path\n",
    "FIGURES_PATH = \"figures\"\n",
    "os.makedirs(FIGURES_PATH, exist_ok=True)\n",
    "# #Define the data folder path\n",
    "DATAFOLDER_PATH = \"datafiles\"\n",
    "os.makedirs(DATAFOLDER_PATH, exist_ok=True)\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  print('Running on CoLab')\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive/')\n",
    "  DATASET_FILE_PATH = \"/content/drive/My Drive/Colab Notebooks/Dataset.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HUwxZvhVuoaB",
   "metadata": {
    "id": "HUwxZvhVuoaB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset: np.ndarray = np.load(DATASET_FILE_PATH)\n",
    "# TODO delete this when we fix performance\n",
    "dataset = dataset[:min(1000000, dataset.size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef26d1d-fe37-430c-8899-22953406249d",
   "metadata": {
    "id": "6ef26d1d-fe37-430c-8899-22953406249d"
   },
   "outputs": [],
   "source": [
    "def create_dataframe_cached(dataset: np.ndarray) -> pd.DataFrame:\n",
    "    #Define the splitter lambda function in order to tokenize the initial string data.\n",
    "    splitter: typing.Callable[[str], list[str]] = lambda s: s.split(\",\")\n",
    "    #Apply the splitter lambda function on the string np array\n",
    "    dataset = np.array([splitter(x) for x in dataset])\n",
    "    #Set the pickle file for storing the initial dataframe\n",
    "    pickle_file = os.path.join(DATAFOLDER_PATH, \"dataframe.pkl\")\n",
    "    #Check the existence of the specified file.\n",
    "    if os.path.exists(pickle_file):\n",
    "        #Load the pickle file\n",
    "        dataframe: pd.DataFrame = pd.read_pickle(pickle_file)\n",
    "        return dataframe\n",
    "    else:\n",
    "        #Create the dataframe object.\n",
    "        dataframe = pd.DataFrame(dataset, columns=['User','Movie','Rating','Date'])\n",
    "        #Convert the string elements of the \"Users\" series into integers\n",
    "        dataframe[\"User\"] = dataframe[\"User\"].apply(lambda s:np.int64(s.replace(\"ur\",\"\")))\n",
    "        #Convert the string elements of the \"Movies\" series into integers\n",
    "        dataframe[\"Movie\"] = dataframe[\"Movie\"].apply(lambda s:np.int64(s.replace(\"tt\",\"\")))\n",
    "        #Convert the string elements of the \"Ratings\" series into integers\n",
    "        dataframe[\"Rating\"] = dataframe[\"Rating\"].apply(lambda s:np.int64(s))\n",
    "        #Convert the string element of \"Dates\" series into datetime Object\n",
    "        dataframe[\"Date\"] = pd.to_datetime(dataframe[\"Date\"])\n",
    "        dataframe.to_pickle(pickle_file)\n",
    "        return dataframe\n",
    "\n",
    "\n",
    "dataframe: pd.DataFrame = create_dataframe_cached(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e2ea4-9604-4394-807d-1ede45da111f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c5e2ea4-9604-4394-807d-1ede45da111f",
    "outputId": "9765417e-f66a-4bc7-cffe-15ca912fdaf3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get the unique users in the dataset.\n",
    "users = dataframe[\"User\"].unique()\n",
    "#Get the number of unique users\n",
    "users_num = len(users)\n",
    "#Get the unique movie items in the dataset.\n",
    "movies = dataframe[\"Movie\"].unique()\n",
    "#Get the number of unique movies\n",
    "movies_num = len(movies)\n",
    "#Get the total number of existing ratings.\n",
    "ratings_num = dataframe.shape[0]\n",
    "#Report the number of unique Users and Movies in the dataset\n",
    "print(\"INITIAL DATASET: {0} number of unique users and {1} of unique movies\".format(users_num, movies_num))\n",
    "#Report the total number of existing ratings in the dataset\n",
    "print(\"INITIAL DATASET: {} total number of existing ratings\".format(ratings_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64464402-12c9-4080-a87d-6251f0d7beb5",
   "metadata": {
    "id": "64464402-12c9-4080-a87d-6251f0d7beb5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_ratings_num_df_cached(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    #Define the pickle file that will store the time span per user dataframe\n",
    "    pickle_file = os.path.join(DATAFOLDER_PATH, \"ratings_num_df.pkl\")\n",
    "    #Check the existence of the previously defined pickle file\n",
    "    if os.path.exists(pickle_file):\n",
    "        #Load the pickle file\n",
    "        ratings_num_df: pd.DataFrame = pd.read_pickle(pickle_file)\n",
    "        return ratings_num_df\n",
    "    else:\n",
    "        ratings_num_df = dataframe.groupby(\"User\")[\"Rating\"].count().sort_values(ascending=False).reset_index(name=\"ratings_num\")\n",
    "        #Save the previously created dataframe to pickle\n",
    "        ratings_num_df.to_pickle(pickle_file)\n",
    "        return ratings_num_df\n",
    "\n",
    "\n",
    "ratings_num_df: pd.DataFrame = create_ratings_num_df_cached(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033c285-a2d3-4daf-9c96-8ebeb47f5103",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "f033c285-a2d3-4daf-9c96-8ebeb47f5103",
    "outputId": "f03c83af-3b7f-4481-df41-b84c77d45af5"
   },
   "outputs": [],
   "source": [
    "def create_ratings_span_df_cached(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    #Set the pickle file that will store the time span per user dataframe\n",
    "    pickle_file = os.path.join(DATAFOLDER_PATH, \"ratings_span_df.pkl\")\n",
    "    if os.path.exists(pickle_file):\n",
    "        ratings_span_df: pd.DataFrame = pd.read_pickle(pickle_file)\n",
    "        return ratings_span_df\n",
    "    else:\n",
    "        ratings_span_df = dataframe.groupby(\"User\")[\"Date\"].apply(lambda date: max(date)-min(date)).sort_values(ascending=False).reset_index(name=\"ratings_span\")\n",
    "        ratings_span_df.to_pickle(pickle_file)\n",
    "        return ratings_span_df\n",
    "\n",
    "\n",
    "def plot_histograms(reduced_ratings_df: pd.DataFrame):\n",
    "    #Generate the frequency histogram for the number of ratings per user\n",
    "    reduced_ratings_df[\"ratings_num\"].plot(kind='hist', title='Frequency of Ratings per User', xticks=range(minimum_ratings, maximum_ratings+1, 25))\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Number of Users')\n",
    "\n",
    "    plt.show()\n",
    "    #Generate the frequency histogram for the time span of ratings per user\n",
    "    reduced_ratings_df[\"ratings_span\"].plot(kind='hist', title='Frequency for time span of Ratings per User')\n",
    "    plt.xlabel('Number of Users')\n",
    "    plt.ylabel('Time range of Ratings (Days)')\n",
    "\n",
    "    plt.show()   \n",
    "\n",
    "ratings_span_df = create_ratings_span_df_cached(dataframe)\n",
    "\n",
    "#Create a new ratings dataframe by joining the previously defined dataframe\n",
    "ratings_df = ratings_num_df.join(ratings_span_df.set_index(\"User\"),on=\"User\")\n",
    "ratings_df[\"ratings_span\"]=ratings_df[\"ratings_span\"].dt.days\n",
    "#Set the threshold values for the minimum and maximum number of Ratings per user\n",
    "minimum_ratings = 100\n",
    "maximum_ratings = 300\n",
    "#Discard all users that do not pertain to the previous range of ratings\n",
    "reduced_ratings_df = ratings_df.loc[(ratings_df[\"ratings_num\"] >= minimum_ratings) & (ratings_df[\"ratings_num\"] <= maximum_ratings)]\n",
    "\n",
    "plot_histograms(reduced_ratings_df)                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d13f9b-ae75-4625-a9ed-2c1f19bdaa7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49d13f9b-ae75-4625-a9ed-2c1f19bdaa7d",
    "outputId": "48ee5c06-6692-46d8-be61-36a5ceaf3e9a"
   },
   "outputs": [],
   "source": [
    "#Get the final dataframe by excluding all users whose ratings fall outside the prespecified range\n",
    "final_df = dataframe.loc[dataframe[\"User\"].isin(reduced_ratings_df[\"User\"])].reset_index()\n",
    "#Drop the links (indices) to the original table\n",
    "final_df = final_df.drop(\"index\", axis=1)\n",
    "#Get the unique users and items in the final dataframe along with the final number of ratings\n",
    "final_users = final_df[\"User\"].unique()\n",
    "final_movies = final_df[\"Movie\"].unique()\n",
    "final_users_num = len(final_users)\n",
    "final_movies_num = len(final_movies)\n",
    "final_ratings_num = len(final_df)\n",
    "\n",
    "#Report the final number of unique users and movies in the dataset\n",
    "print(\"REDUCED DATASET: {0} number of unique users and {1} number of unique movies\".format(final_users_num, final_movies_num))\n",
    "#Report the final number of existing ratings in the dataset\n",
    "print(\"REDUCED DATASET: {} number of existing ratings in the dataset\".format(final_ratings_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad131c64-257f-4f1b-9918-e005d7e96910",
   "metadata": {
    "id": "ad131c64-257f-4f1b-9918-e005d7e96910"
   },
   "outputs": [],
   "source": [
    "#We need to reset the users and items IDs in order to be able to construct a network of users and Movies. \n",
    "#Users and Movies IDs should be consecutive in the [1..final_users_num] and [1...final_movies_num]\n",
    "#Initially, we need to acquire the sorted versions of the user and movies\n",
    "sorted_final_users = np.sort(final_users)\n",
    "sorted_final_movies = np.sort(final_movies)\n",
    "#Generate the dictionary of final users as a mapping of the following \n",
    "#sorted_final_users --> [0...final_users_num-1]\n",
    "final_users_dict = dict(zip(sorted_final_users,list(range(0,final_users_num))))\n",
    "#Generate the dictionary of final items as a mapping of the following\n",
    "final_movies_dict = dict(zip(sorted_final_movies,list(range(0,final_movies_num))))\n",
    "#Apply the previously defined dictionary-based maps on the users and movies columns of the final dataframe\n",
    "final_df[\"User\"] = final_df[\"User\"].map(final_users_dict)\n",
    "final_df[\"Movie\"] = final_df[\"Movie\"].map(final_movies_dict)\n",
    "#Get a grouped version of the original dataframe based on the unique final users\n",
    "users_group_df = final_df.groupby(\"User\")\n",
    "#Initialize the adjacency matrix which stores the connection status for pair of users in the recommendation network\n",
    "W = np.zeros((final_users_num, final_users_num))\n",
    "#Iinitialize the matrix storing the number of commonly rated items for a pair of users\n",
    "CommonRatings = np.zeros((final_users_num, final_users_num))\n",
    "#Initialize the matrix of common ratings\n",
    "#Matrix W will be of size [final_users_num x final_users_num],\n",
    "#Let U = {u1, u2,...,un} be the final set of users and I = {i1,i2,...,im}\n",
    "#final set of movies. By considering the function Fi: U -> P(I) where\n",
    "#P(I) is the powerset of I, Fi(u) returns the subset of items that has been rated by user u. \n",
    "#In this context, the edge weight between any given pair of users (u,v) will be computed as:\n",
    "#\n",
    "#          |Intersection(Fi(u)),Fi(v))|\n",
    "#W(u,v) =  -----------------------------\n",
    "#               |Union(Fi(u),Fi(v))|\n",
    "#\n",
    "#\n",
    "#In order to speed up the construction of the adjacency matrix for the ratings network, \n",
    "#construct a dictionary object that will store a set of rated items for each unique user.\n",
    "user_items_dict = {}\n",
    "# for user in final_users:\n",
    "    #print(user)\n",
    "    # user_index = final_users_dict[user]\n",
    "    # user_movies = set(users_group_df.get_group(user_index)[\"Movie\"])\n",
    "    # user_items_dict[user_index] = user_movies\n",
    "                                                 \n",
    "# Initialize the dictionary for storing the set of rated items for each user\n",
    "user_items_dict = {}\n",
    "# print(final_users_dict)\n",
    "# print(sorted_final_users)\n",
    "# print(final_users_dict)\n",
    "# For each unique user, find the set of movies that they rated\n",
    "for user in final_users:\n",
    "    if user in final_users_dict:\n",
    "        user_index = final_users_dict[user]\n",
    "        user_movies = set(users_group_df.get_group(user_index)[\"Movie\"])\n",
    "        user_items_dict[user_index] = user_movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0327c71-7ac0-496c-b53c-083ddbbc36de",
   "metadata": {
    "id": "c0327c71-7ac0-496c-b53c-083ddbbc36de"
   },
   "outputs": [],
   "source": [
    "user_ids = list(user_items_dict.keys())\n",
    "user_ids.sort()\n",
    "#Generate the sorted version of the dictionary\n",
    "user_items_dict = {user_index:user_items_dict[user_index] for user_index in user_ids}\n",
    "#Set the pickle file that will store the graph adjacency matrix W.\n",
    "pickle_file_weights = os.path.join(DATAFOLDER_PATH, \"w\")\n",
    "pickle_file_common_ratings = os.path.join(DATAFOLDER_PATH, \"common_ratings\")\n",
    "#Check the existence of the previously defined pickle file\n",
    "if os.path.exists(pickle_file_weights) & os.path.exists(pickle_file_common_ratings):\n",
    "    #Load the pickle file\n",
    "    W = np.load(pickle_file_weights)\n",
    "    CommonRatings = np.load(pickle_file_common_ratings)\n",
    "else:\n",
    "    for source_user in user_items_dict.keys():\n",
    "        for target_user in user_items_dict.keys():\n",
    "            intersection_items = user_items_dict[source_user].intersection(user_items_dict[target_user])\n",
    "            union_items = user_items_dict[source_user].union(user_items_dict[target_user])\n",
    "            W[source_user, target_user] = len(intersection_items)/len(union_items)\n",
    "            CommonRatings[source_user, target_user] = len(intersection_items)\n",
    "    np.save(pickle_file_weights,W)\n",
    "    np.save(pickle_file_common_ratings,CommonRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2310ff25-7ad9-4cf6-b6f0-ada4575d6362",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2310ff25-7ad9-4cf6-b6f0-ada4575d6362",
    "outputId": "1b3c10ab-6be2-4570-bc96-b34c8f12f762"
   },
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77097013-5e4f-4e3c-832a-68b3f262e21f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77097013-5e4f-4e3c-832a-68b3f262e21f",
    "outputId": "2a70af82-d73f-466c-bf97-d2d8c9a59a57"
   },
   "outputs": [],
   "source": [
    "CommonRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4959ffd5-63d3-4507-91da-77a2adbdd318",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "4959ffd5-63d3-4507-91da-77a2adbdd318",
    "outputId": "bd323ce2-fb87-47dc-b0eb-aee8f0b5bada"
   },
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y7kiJK1IQUYL",
   "metadata": {
    "id": "Y7kiJK1IQUYL"
   },
   "source": [
    "#Δημιουργούμε έναν πίνακα χρηστών - ταινιών \n",
    "(οι χρήστες βρίσκονται στις γραμμές και οι ταινίες στις στήλες του πίνακα)\n",
    "όπου τα στοιχεία του πίνακα είναι από 1 - 10. Εάν ο χρήστης δεν έχει αξιολογήσει την ταινία,\n",
    "η αξιολόγηση που θα ανατεθεί είναι 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903020b4-0070-41c3-90ef-46f8915f7a3e",
   "metadata": {
    "id": "903020b4-0070-41c3-90ef-46f8915f7a3e"
   },
   "outputs": [],
   "source": [
    "# Create a pivot table of user-movie ratings\n",
    "ratings_matrix = final_df.pivot_table(index='User', columns='Movie', values='Rating')\n",
    "ratings_matrix = ratings_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15596e9-ec57-411d-952a-bc6bcd265942",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "b15596e9-ec57-411d-952a-bc6bcd265942",
    "outputId": "1fcd8d20-78a7-48d3-aa11-3da13fa9c093"
   },
   "outputs": [],
   "source": [
    "ratings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceaf6a2-e9e7-4067-b01f-515bc34f59a9",
   "metadata": {
    "id": "3ceaf6a2-e9e7-4067-b01f-515bc34f59a9"
   },
   "outputs": [],
   "source": [
    "from pyclustering.cluster.kmeans import kmeans, kmeans_visualizer\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.samples.definitions import FCPS_SAMPLES\n",
    "from pyclustering.utils import read_sample\n",
    "from pyclustering.cluster.kmeans import kmeans\n",
    "from pyclustering.utils.metric import type_metric, distance_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KvkvmxZ-QpTc",
   "metadata": {
    "id": "KvkvmxZ-QpTc"
   },
   "source": [
    "Θέλουμε να δημιουργήσουμε τον πίνακα βαρών \"λ\" των χρηστών. Τον πίνακα αξιολογήσεων δηλαδή όπου η τιμή της αξιολόγησης είναι 1 εάν η ταινία έχει αξιολογηθεί από τον χρήστη ή 0 εάν δεν έχει αξιολογηθεί"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26dcef5-1f13-48b8-9445-74d3ce13a0ce",
   "metadata": {
    "id": "a26dcef5-1f13-48b8-9445-74d3ce13a0ce"
   },
   "outputs": [],
   "source": [
    "# Threshold\n",
    "threshold = 1\n",
    "\n",
    "# Transform to binary\n",
    "binary_matrix = np.where(ratings_matrix >= threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81271815-7f18-4890-a83a-8686c293dd30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81271815-7f18-4890-a83a-8686c293dd30",
    "outputId": "b6aa5a3d-57f1-4655-e036-a44cfe7a5b2c"
   },
   "outputs": [],
   "source": [
    "binary_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f829cfd-4fa3-4ead-820f-2e13e332b22a",
   "metadata": {
    "id": "1f829cfd-4fa3-4ead-820f-2e13e332b22a"
   },
   "outputs": [],
   "source": [
    "# Convert the matrix to a numpy array\n",
    "matrix_array = ratings_matrix.to_numpy()\n",
    "\n",
    "# Create a dictionary that maps each row of the matrix to its index\n",
    "# matrix_dict = {tuple(row): i for i, row in enumerate(matrix_array)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QJ0NaNSUrfyC",
   "metadata": {
    "id": "QJ0NaNSUrfyC"
   },
   "source": [
    "# ***Αλγόριθμοι Ομαδοποίησης Δεδομένων***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NJuh-Qpcya-i",
   "metadata": {
    "id": "NJuh-Qpcya-i"
   },
   "source": [
    "**Χρήση της Weighted Euclidean Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R8xa7QCu5SG9",
   "metadata": {
    "id": "R8xa7QCu5SG9"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, cdist\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def pairwise_weighted_euclidean_distance(X, weights):\n",
    "    # Find the indices of the rated movies for each pair of users\n",
    "    rated_movies = (weights_sparse.T @ weights_sparse) > 0\n",
    "\n",
    "    # Select only the rated movies for each pair of users\n",
    "    X_rated = X_sparse[:, rated_movies]\n",
    "    \n",
    "    # Calculate the pairwise weighted Euclidean distance between \n",
    "    #users who have rated the same movie\n",
    "    return cdist(X, metric='euclidean')\n",
    "\n",
    "def kmeans_pairwise_weighted_euclidean(X, weights, k, max_iters=2):\n",
    "\n",
    "    n, m = X.shape\n",
    "    centroids = X[np.random.choice(n, k, replace=False)]\n",
    "    distances = pairwise_weighted_euclidean_distance(X, weights)\n",
    "    for i in range(max_iters):\n",
    "        # Assign points to clusters\n",
    "        cluster_assignments = np.argmin(distances, axis=1)\n",
    "\n",
    "        # Recalculate cluster centroids\n",
    "        for j in range(k):\n",
    "            cluster_points = X[cluster_assignments == j]\n",
    "            if len(cluster_points) > 0:\n",
    "                centroids[j] = np.average(cluster_points, axis=0)\n",
    "\n",
    "        # Update distances to centroids\n",
    "        distances = pairwise_weighted_euclidean_distance(X, weights)\n",
    "\n",
    "    return cluster_assignments, centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc589cb-6d00-490b-aaf4-bb4413b5bf39",
   "metadata": {
    "id": "4dc589cb-6d00-490b-aaf4-bb4413b5bf39"
   },
   "outputs": [],
   "source": [
    "# Calculate the weighted Euclidean distance matrix\n",
    "D = np.zeros((ratings_matrix.shape[0], ratings_matrix.shape[0]))\n",
    "\n",
    "for i in range(ratings_matrix.shape[0]):\n",
    "    for j in range(i, ratings_matrix.shape[0]):\n",
    "        d = np.sqrt(np.sum(binary_matrix[i,:]*binary_matrix[j,:] * (ratings_matrix.iloc[i,:] - ratings_matrix.iloc[j,:])**2))\n",
    "        D[i,j] = d\n",
    "        D[j,i] = d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a45355-d4a3-417a-8580-18f1e6c986cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12a45355-d4a3-417a-8580-18f1e6c986cd",
    "outputId": "22973569-c3a8-4b6f-e772-44a7789f4b9e"
   },
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wQx00tek0XXq",
   "metadata": {
    "id": "wQx00tek0XXq"
   },
   "source": [
    "# Clustering users using K-means\n",
    " We want to start by creating the symmetric D matrix which contains the pairwise weighted Euclidean distance for every pair of users.\n",
    " We calculate the distance between each user using \n",
    "*   dist_{u,v}=\\sum_{k=1}^{n}\\sqrt{|R_{u}(k) - R_{v}(k)|λ_{u}(k)λ_{v}(k)}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6911e7b-7bd6-4e50-9197-d57843b540bb",
   "metadata": {
    "id": "a6911e7b-7bd6-4e50-9197-d57843b540bb"
   },
   "outputs": [],
   "source": [
    "# Calculate the pairwise weighted Euclidean distance matrix\n",
    "n = ratings_matrix.shape[0]\n",
    "n = 100\n",
    "Dist_euclidean = np.zeros((n, n))\n",
    "for i in range(n):\n",
    "  for j in range(i, n):\n",
    "      d = np.sqrt(np.sum(binary_matrix[i,:] * binary_matrix[j,:] * (ratings_matrix.loc[i,:] - ratings_matrix.loc[j,:])**2))\n",
    "      Dist_euclidean[i,j] = d\n",
    "      Dist_euclidean[j,i] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a9ee9-1b48-46e5-903a-cf7c9f3a7f52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "366a9ee9-1b48-46e5-903a-cf7c9f3a7f52",
    "outputId": "d07e935a-4234-4c1c-ace9-38e7a1f5ee67"
   },
   "outputs": [],
   "source": [
    "df_euclidean = pd.DataFrame(Dist_euclidean)\n",
    "df_euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NWWDOjPGRCYw",
   "metadata": {
    "id": "NWWDOjPGRCYw"
   },
   "source": [
    "Στον πίνακα αποστάσεων που έχουμε δημιουργήσει, θα τρέξουμε τον αλγόριθμο k-means ώστε να αποτιμήσουμε την ομοιότητα των χρηστών χρησιμοποιώντας τις μεταξύ τους αποστάσεις."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c29300d-deb0-4ebd-b250-aa714a50a0a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c29300d-deb0-4ebd-b250-aa714a50a0a5",
    "outputId": "7f2c694c-5bae-473f-c66e-ab3af3d65415"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Cluster the users using K-means\n",
    "kmeans = KMeans(n_clusters=5).fit(Dist_euclidean)\n",
    "\n",
    "# Get the cluster labels\n",
    "labels_euclidean = kmeans.labels_\n",
    "\n",
    "# Print the labels\n",
    "print(labels_euclidean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6hCiZ2wfG2_S",
   "metadata": {
    "id": "6hCiZ2wfG2_S"
   },
   "source": [
    "Cluster the users, by using a custom \n",
    "dist = 1 - np.abs(np.sum(R_u*R_v*weights_u*weights_l)/(np.sqrt(R^2_u*weights_u*weights_l)*np.sqrt(R^2_v*weights_u*weights_l)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2411e0-9be1-4d00-b1c0-7e58650da9bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a2411e0-9be1-4d00-b1c0-7e58650da9bd",
    "outputId": "d045b06b-58c5-4498-eb89-01d6122f456e"
   },
   "outputs": [],
   "source": [
    "# Calculate the pairwise weighted Cosine distance matrix\n",
    "n = ratings_matrix.shape[0]\n",
    "n = 100\n",
    "Dist_cosine = np.zeros((n, n))\n",
    "for i in range(n):\n",
    "  for j in range(i, n):\n",
    "      d = 1 - np.abs(np.sum(binary_matrix[i,:] * binary_matrix[j,:] * ratings_matrix.loc[i,:] * ratings_matrix.loc[j,:]) / (np.sqrt(np.sum(binary_matrix[i,:] * binary_matrix[j,:] * ratings_matrix.loc[i,:])* np.sqrt(np.sum(binary_matrix[i,:] * binary_matrix[j,:] * ratings_matrix.loc[j,:])))))\n",
    "      Dist_cosine[i,j] = d\n",
    "      Dist_cosine[j,i] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cOc0082IqT2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "8cOc0082IqT2",
    "outputId": "0fe21998-1009-4a36-a1ab-a643c5e45412"
   },
   "outputs": [],
   "source": [
    "df_cosine = pd.DataFrame(Dist_cosine)\n",
    "df_cosine = df_cosine.replace(np.nan, 0)\n",
    "df_cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9IvMaCXORgXf",
   "metadata": {
    "id": "9IvMaCXORgXf"
   },
   "source": [
    "Στον πίνακα αποστάσεων που έχουμε δημιουργήσει, θα τρέξουμε τον αλγόριθμο k-means ώστε να αποτιμήσουμε την ομοιότητα των χρηστών χρησιμοποιώντας τις μεταξύ τους αποστάσεις."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1K3Ry-W0IN74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1K3Ry-W0IN74",
    "outputId": "9cfc75b0-b328-4f22-c275-8e943899dc6c"
   },
   "outputs": [],
   "source": [
    "# Cluster the users using K-means\n",
    "kmeans = KMeans(n_clusters=5, n_init=10).fit(df_cosine)\n",
    "\n",
    "# Get the cluster labels\n",
    "labels_cosine = kmeans.labels_\n",
    "\n",
    "# Print the labels\n",
    "print(labels_cosine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s_MLiRK6Rh6E",
   "metadata": {
    "id": "s_MLiRK6Rh6E"
   },
   "source": [
    "# Elbow Method\n",
    "Χρησιμοποιούμε την elbow method ώστε να επιλέξουμε τον βέλτιστο αριθμό clusters στον οποίο θα διαχωριστούν τα δεδομένα χρησιμοποιώντας τον k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ITnxc3WJec5",
   "metadata": {
    "id": "9ITnxc3WJec5"
   },
   "outputs": [],
   "source": [
    "def elbow_method(df: pd.DataFrame, max_iter: int):\n",
    "  distortions = []\n",
    "  K = range(1,max_iter)\n",
    "  for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k, n_init=10)\n",
    "    kmeanModel.fit(df)\n",
    "    distortions.append(kmeanModel.inertia_)\n",
    "  plt.figure(figsize=(16,8))\n",
    "  plt.plot(K, distortions, 'bx-')\n",
    "  plt.xlabel('k')\n",
    "  plt.ylabel('Distortion')\n",
    "  plt.title('The Elbow Method showing the optimal k')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UJgM52L7G1NU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 824
    },
    "id": "UJgM52L7G1NU",
    "outputId": "f63c5aa9-a7be-473e-a46c-1a053dddf6f6"
   },
   "outputs": [],
   "source": [
    "#Using the elbow method on Cosine distance\n",
    "elbow_method(df_cosine, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zOCZ4XZyHiKU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 824
    },
    "id": "zOCZ4XZyHiKU",
    "outputId": "4ac0330e-d9eb-4555-f7c5-70d46339d08b"
   },
   "outputs": [],
   "source": [
    "#Using the elbow method on Euclidean distance\n",
    "elbow_method(Dist_euclidean, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P1K1uNDHW3m4",
   "metadata": {
    "id": "P1K1uNDHW3m4"
   },
   "source": [
    "First, we have to modify our df in order to keep the first n users and assign our labels to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2oALEUXvXAqJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "2oALEUXvXAqJ",
    "outputId": "07f73b73-0e72-4daf-ba32-9ecc5d52f23a"
   },
   "outputs": [],
   "source": [
    "ratings_matrix = ratings_matrix.head(100)\n",
    "ratings_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AYNf6PMYP-QC",
   "metadata": {
    "id": "AYNf6PMYP-QC"
   },
   "source": [
    "Next, we'll use the PCA method in order to reduce the dimensionality of our matrix and plot our clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ejOUlMYaQOEV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejOUlMYaQOEV",
    "outputId": "1650656b-b386-4342-e83c-2f37ea899b60"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# instantiate StandardScaler and PCA with 2 components for 2D scatter plot\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# fit and transform the ratings matrix\n",
    "ratings_pca = pca.fit_transform(ratings_matrix)\n",
    "\n",
    "# print the explained variance ratio for each component\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UCxdIcygTFor",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "UCxdIcygTFor",
    "outputId": "dc8cff0c-4d5f-4116-dcfd-1d5373a0187f"
   },
   "outputs": [],
   "source": [
    "# create a new dataframe with the PCA components and user index\n",
    "df_pca = pd.DataFrame(ratings_pca, index=range(0, 100))\n",
    "df_pca['Cluster'] = labels_euclidean\n",
    "df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4u_fFobUb_k",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "a4u_fFobUb_k",
    "outputId": "9e1c8fe3-879b-4b20-94c3-1701086e5912",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a scatter plot of the PCA components\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for label, color in zip(df_pca['Cluster'].unique(), ['blue', 'red', 'green', 'orange', 'purple']):\n",
    "    group = df_pca.groupby('Cluster').get_group(label)\n",
    "    ax.scatter(group[0], group[1], c=color, label=f'Cluster {label}')\n",
    "\n",
    "# set the axis labels and title\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "ax.set_title('PCA Transformed User-Movie Ratings')\n",
    "\n",
    "# add a legend\n",
    "ax.legend()\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "history_visible": true,
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
